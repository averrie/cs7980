{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, gzip, io, math\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIRS = [\n",
    "    r\".\\\\bluesky\\\\dataset\\\\labeled_all_posts.json\",\n",
    "    r\".\\\\truthsocial\\\\dataset\\\\labeled_all_posts.json\",\n",
    "]\n",
    "\n",
    "SAVE_DIR = Path(\"./label_eda\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "search_terms = {\n",
    "    \"Abortion and Reproductive Policy\": {\n",
    "        \"left\": [\"reproductive rights\", \"pro-choice\", \"abortion access\", \"women's rights\"],\n",
    "        \"right\": [\"pro-life\", \"unborn\", \"sanctity of life\", \"heartbeat bill\"],\n",
    "        \"neutral\": [\"abortion law\", \"abortion policy\", \"Roe v. Wade\", \"Planned Parenthood\"],\n",
    "    },\n",
    "    \"Gun Policy and Firearms Regulation\": {\n",
    "        \"left\": [\"gun control\", \"assault weapons ban\", \"background checks\"],\n",
    "        \"right\": [\"gun rights\", \"Second Amendment\", \"2A\", \"constitutional carry\"],\n",
    "        \"neutral\": [\"firearms policy\", \"gun laws\", \"gun ownership\"],\n",
    "    },\n",
    "    \"Climate and Environmental Policy\": {\n",
    "        \"left\": [\"climate crisis\", \"renewable energy\", \"green new deal\"],\n",
    "        \"right\": [\"energy independence\", \"fossil fuels\", \"climate hoax\"],\n",
    "        \"neutral\": [\"climate change\", \"carbon emissions\", \"environmental regulation\", \"Paris Agreement\"],\n",
    "    },\n",
    "    \"Healthcare and Insurance Reform\": {\n",
    "        \"left\": [\"universal healthcare\", \"Medicare for All\", \"public option\"],\n",
    "        \"right\": [\"health freedom\", \"government overreach\", \"private insurance\"],\n",
    "        \"neutral\": [\"healthcare reform\", \"Affordable Care Act\", \"health insurance policy\"],\n",
    "    },\n",
    "    \"Immigration and Border Policy\": {\n",
    "        \"left\": [\"immigrant rights\", \"DACA\", \"asylum seekers\", \"family separation\"],\n",
    "        \"right\": [\"border crisis\", \"illegal immigration\", \"build the wall\"],\n",
    "        \"neutral\": [\"immigration policy\", \"border security\", \"visa policy\"],\n",
    "    },\n",
    "    \"LGBTQ+ and Civil Rights\": {\n",
    "        \"left\": [\"LGBTQ+ rights\", \"trans rights\", \"marriage equality\"],\n",
    "        \"right\": [\"religious freedom\", \"parental rights\", \"traditional values\"],\n",
    "        \"neutral\": [\"civil rights\", \"anti-discrimination\", \"gender identity policy\"],\n",
    "    },\n",
    "    \"Voting and Election Policy\": {\n",
    "        \"left\": [\"voting rights\", \"voter suppression\", \"expand mail-in voting\"],\n",
    "        \"right\": [\"election integrity\", \"voter fraud\", \"secure elections\"],\n",
    "        \"neutral\": [\"election reform\", \"voter ID laws\", \"ballot access\"],\n",
    "    },\n",
    "    \"Economic Inequality and Taxation\": {\n",
    "        \"left\": [\"wealth tax\", \"economic justice\", \"raise minimum wage\"],\n",
    "        \"right\": [\"tax burden\", \"job creators\", \"free market\"],\n",
    "        \"neutral\": [\"tax policy\", \"income inequality\", \"economic mobility\"],\n",
    "    },\n",
    "    \"Policing and Criminal Justice Reform\": {\n",
    "        \"left\": [\"police reform\", \"defund the police\", \"mass incarceration\"],\n",
    "        \"right\": [\"law and order\", \"back the blue\", \"crime wave\"],\n",
    "        \"neutral\": [\"criminal justice reform\", \"public safety\", \"police accountability\"],\n",
    "    },\n",
    "    \"Free Speech and Content Regulation\": {\n",
    "        \"left\": [\"hate speech\", \"content moderation\", \"misinformation\"],\n",
    "        \"right\": [\"free speech\", \"censorship\", \"cancel culture\"],\n",
    "        \"neutral\": [\"First Amendment\", \"online speech\", \"platform policy\"],\n",
    "    },\n",
    "    \"Affirmative Action and Education Policy\": {\n",
    "        \"left\": [\"affirmative action\", \"diversity in education\", \"racial equity\"],\n",
    "        \"right\": [\"merit-based admissions\", \"colorblind policy\", \"reverse discrimination\"],\n",
    "        \"neutral\": [\"college admissions\", \"education policy\", \"Supreme Court decision\"],\n",
    "    },\n",
    "    \"Drug Policy and Substance Regulation\": {\n",
    "        \"left\": [\"drug decriminalization\", \"harm reduction\", \"marijuana legalization\"],\n",
    "        \"right\": [\"war on drugs\", \"fentanyl crisis\", \"tough on crime\"],\n",
    "        \"neutral\": [\"drug policy\", \"opioid epidemic\", \"controlled substances\"],\n",
    "    },\n",
    "    \"Foreign Policy and National Defense\": {\n",
    "        \"left\": [\"diplomacy\", \"humanitarian aid\", \"anti-war\"],\n",
    "        \"right\": [\"military strength\", \"America First\", \"peace through strength\"],\n",
    "        \"neutral\": [\"foreign policy\", \"NATO\", \"defense spending\", \"Ukraine war\"],\n",
    "    },\n",
    "    \"Technology and Internet Regulation\": {\n",
    "        \"left\": [\"tech accountability\", \"data privacy\", \"AI regulation\"],\n",
    "        \"right\": [\"free market innovation\", \"anti-censorship\", \"Big Tech bias\"],\n",
    "        \"neutral\": [\"technology policy\", \"Section 230\", \"AI ethics\"],\n",
    "    },\n",
    "    \"Race and Education Curriculum\": {\n",
    "        \"left\": [\"racial justice education\", \"anti-racism curriculum\", \"diversity training\"],\n",
    "        \"right\": [\"critical race theory\", \"parental rights in education\", \"woke indoctrination\"],\n",
    "        \"neutral\": [\"education curriculum\", \"teaching history\", \"school policy\"],\n",
    "    },\n",
    "    \"Sex Education and Family Policy\": {\n",
    "        \"left\": [\"comprehensive sex education\", \"LGBTQ-inclusive curriculum\"],\n",
    "        \"right\": [\"abstinence education\", \"parental consent\", \"family values\"],\n",
    "        \"neutral\": [\"sex education policy\", \"school curriculum\", \"health education\"],\n",
    "    },\n",
    "    \"Basic Income and Welfare Programs\": {\n",
    "        \"left\": [\"universal basic income\", \"social safety net\", \"poverty relief\"],\n",
    "        \"right\": [\"welfare dependency\", \"personal responsibility\", \"work requirements\"],\n",
    "        \"neutral\": [\"welfare policy\", \"income support\", \"economic assistance\"],\n",
    "    },\n",
    "    \"Trade and Economic Policy\": {\n",
    "        \"left\": [\"fair trade\", \"labor rights\", \"climate-friendly trade\"],\n",
    "        \"right\": [\"free trade\", \"tariffs\", \"America First trade\"],\n",
    "        \"neutral\": [\"trade policy\", \"import/export\", \"trade agreements\"],\n",
    "    },\n",
    "    \"Social Security and Retirement Policy\": {\n",
    "        \"left\": [\"protect social security\", \"expand benefits\"],\n",
    "        \"right\": [\"entitlement reform\", \"reduce spending\", \"privatize social security\"],\n",
    "        \"neutral\": [\"retirement policy\", \"social security funding\", \"aging population\"],\n",
    "    },\n",
    "    \"National Security and Civil Liberties\": {\n",
    "        \"left\": [\"surveillance reform\", \"privacy rights\", \"anti-war movement\"],\n",
    "        \"right\": [\"national security\", \"border protection\", \"patriotism\"],\n",
    "        \"neutral\": [\"counterterrorism\", \"cybersecurity\", \"civil liberties\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build framing map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_to_topic = {}\n",
    "kw_to_bucket = {}\n",
    "for topic, buckets in search_terms.items():\n",
    "    for bucket, kws in buckets.items():\n",
    "        for kw in kws:\n",
    "            k = kw.strip().lower()\n",
    "            kw_to_topic[k] = topic\n",
    "            kw_to_bucket[k] = bucket  # 'left' | 'right' | 'neutral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_paths(root: Path):\n",
    "    exts = {\".json\", \".jsonl\", \".ndjson\", \".json.gz\", \".jsonl.gz\", \".ndjson.gz\"}\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if p.suffix.lower() in exts or \"\".join(p.suffixes).lower().endswith(\".json.gz\") or \"\".join(p.suffixes).lower().endswith(\".jsonl.gz\") or \"\".join(p.suffixes).lower().endswith(\".ndjson.gz\"):\n",
    "            yield p\n",
    "\n",
    "def open_text(path: Path):\n",
    "    if str(path).endswith(\".gz\"):\n",
    "        return io.TextIOWrapper(gzip.open(path, \"rb\"), encoding=\"utf-8\")\n",
    "    return open(path, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "def iter_records_from_file(path: Path):\n",
    "    with open_text(path) as f:\n",
    "        head = f.read(2048)\n",
    "        f.seek(0)\n",
    "        # if first non-space char is '[', the file is a JSON array\n",
    "        first = head.lstrip()[:1]\n",
    "        if first == \"[\":\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    for obj in data:\n",
    "                        if isinstance(obj, dict):\n",
    "                            yield obj\n",
    "                elif isinstance(data, dict):\n",
    "                    yield data\n",
    "            except Exception:\n",
    "                # fallback to line-iter if parsing large array fails for some reason\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    try:\n",
    "                        obj = json.loads(line)\n",
    "                        if isinstance(obj, dict):\n",
    "                            yield obj\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        else:\n",
    "            # treat as jsonl\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    obj = json.loads(line)\n",
    "                    if isinstance(obj, dict):\n",
    "                        yield obj\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "def normalize_label(x):\n",
    "    if not x:\n",
    "        return None\n",
    "    t = str(x).strip().lower()\n",
    "    if t in (\"left\", \"l\"):\n",
    "        return \"Left\"\n",
    "    if t in (\"right\", \"r\"):\n",
    "        return \"Right\"\n",
    "    if t in (\"neutral\", \"centre\", \"center\", \"centrist\", \"n\"):\n",
    "        return \"Neutral\"\n",
    "    return str(x).strip()\n",
    "\n",
    "def safe_meta(meta):\n",
    "    # expected meta fields\n",
    "    topic = meta.get(\"topic\")\n",
    "    matched_keyword = meta.get(\"matched_keyword\")\n",
    "    platform = meta.get(\"platform\")\n",
    "    label = normalize_label(meta.get(\"llm_label\"))\n",
    "    return topic, matched_keyword, platform, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed records: seen=132,459, used=132,459\n"
     ]
    }
   ],
   "source": [
    "# count by (platform, topic, matched_keyword, framing_bucket, llm_label)\n",
    "C_kw = Counter()\n",
    "\n",
    "# also aggregate by (platform, topic, llm_label)\n",
    "C_topic = Counter()\n",
    "\n",
    "n_seen = 0\n",
    "n_used = 0\n",
    "\n",
    "for d in DATA_DIRS:\n",
    "    root = Path(d)\n",
    "    if not root.exists():\n",
    "        print(f\"[WARN] Missing: {root}\")\n",
    "        continue\n",
    "\n",
    "    if root.is_file():\n",
    "        paths = [root]\n",
    "    else:\n",
    "        paths = iter_paths(root)\n",
    "    \n",
    "    for path in paths:\n",
    "        for rec in iter_records_from_file(path):\n",
    "            n_seen += 1\n",
    "            meta = rec.get(\"__meta__\", {}) or {}\n",
    "            topic, matched_keyword, platform, label = safe_meta(meta)\n",
    "            if not (topic and matched_keyword and platform and label):\n",
    "                continue\n",
    "            \n",
    "            # normalize keyword for framing lookup\n",
    "            kw_norm = matched_keyword.strip().lower()\n",
    "            framing = kw_to_bucket.get(kw_norm, None)\n",
    "        \n",
    "            # if topic missing or disagreeing, accept the meta-provided topic\n",
    "            C_kw[(platform, topic, matched_keyword, framing, label)] += 1\n",
    "            C_topic[(platform, topic, label)] += 1\n",
    "            n_used += 1\n",
    "\n",
    "print(f\"Processed records: seen={n_seen:,}, used={n_used:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kw = pd.DataFrame(\n",
    "    [(plat, topic, kw, framing if framing else \"unknown\", label, cnt)\n",
    "    for (plat, topic, kw, framing, label), cnt in C_kw.items()],\n",
    "    columns=[\"platform\", \"topic\", \"matched_keyword\", \"framing_bucket\", \"llm_label\", \"count\"]\n",
    ")\n",
    "\n",
    "df_topic = pd.DataFrame(\n",
    "    [(plat, topic, label, cnt)\n",
    "    for (plat, topic, label), cnt in C_topic.items()],\n",
    "    columns=[\"platform\", \"topic\", \"llm_label\", \"count\"]\n",
    ")\n",
    "\n",
    "def add_props(df, group_cols, count_col=\"count\", prop_col=\"prop\"):\n",
    "    g = df.groupby(group_cols, dropna=False)[count_col].transform(\"sum\")\n",
    "    out = df.copy()\n",
    "    out[prop_col] = out[count_col] / g.replace({0: pd.NA})\n",
    "    return out\n",
    "\n",
    "df_kw = add_props(df_kw, [\"platform\", \"topic\", \"matched_keyword\"])\n",
    "df_topic = add_props(df_topic, [\"platform\", \"topic\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framing vs Label agreement\n",
    "For keywords that belong to a framing bucket (left/right/neutral), what % of LLM labels match that bucket?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_framing(row):\n",
    "    fb = str(row[\"framing_bucket\"]).lower()\n",
    "    lab = str(row[\"llm_label\"]).lower()\n",
    "    return 1 if fb in (\"left\",\"right\",\"neutral\") and lab == fb else 0\n",
    "\n",
    "df_kw[\"align\"] = df_kw.apply(matches_framing, axis=1)\n",
    "# alignment rate computed at keyword granularity\n",
    "align_kw = (df_kw\n",
    "            .groupby([\"platform\", \"topic\", \"matched_keyword\", \"framing_bucket\"], dropna=False)\n",
    "            .apply(lambda g: (g[\"count\"] * g[\"align\"]).sum() / g[\"count\"].sum(), include_groups=False)\n",
    "            .reset_index(name=\"alignment_rate\"))\n",
    "\n",
    "# Framing-bucket-level label distributions\n",
    "framing_dist = (df_kw\n",
    "    .groupby([\"platform\", \"topic\", \"framing_bucket\", \"llm_label\"], dropna=False)[\"count\"]\n",
    "    .sum().reset_index())\n",
    "framing_dist = add_props(framing_dist, [\"platform\", \"topic\", \"framing_bucket\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross platform comparison and KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_vector(df, key_cols):\n",
    "    # returns dict: key -> dict(label->prob) with Laplace smoothing\n",
    "    out = {}\n",
    "    base = df.groupby(key_cols + [\"llm_label\"])[\"count\"].sum().reset_index()\n",
    "    for key, g in base.groupby(key_cols):\n",
    "        tot = g[\"count\"].sum()\n",
    "        # Laplace smoothing\n",
    "        labels = [\"Left\",\"Right\",\"Neutral\"]\n",
    "        vec = {}\n",
    "        for lab in labels:\n",
    "            v = int(g.loc[g[\"llm_label\"]==lab, \"count\"].sum())\n",
    "            vec[lab] = (v + 1) / (tot + len(labels))\n",
    "        out[key] = vec\n",
    "    return out\n",
    "\n",
    "def kl(p, q):\n",
    "    # KL(p||q) with base e\n",
    "    eps = 1e-12\n",
    "    return sum(pi * math.log((pi+eps)/(qi+eps)) for (pi, qi) in zip(p, q))\n",
    "\n",
    "# topic-level distributions per platform\n",
    "topic_vecs = label_vector(df_topic, [\"platform\",\"topic\"])\n",
    "\n",
    "rows_kl = []\n",
    "for topic in df_topic[\"topic\"].unique():\n",
    "    p = topic_vecs.get((\"truthsocial\", topic))\n",
    "    q = topic_vecs.get((\"bluesky\", topic))\n",
    "    if p and q:\n",
    "        labels = [\"Left\",\"Right\",\"Neutral\"]\n",
    "        P = [p[l] for l in labels]\n",
    "        Q = [q[l] for l in labels]\n",
    "        rows_kl.append({\"topic\": topic,\n",
    "                        \"kl_truth_vs_blue\": kl(P, Q),\n",
    "                        \"truth_LRN\": P,\n",
    "                        \"blue_LRN\": Q})\n",
    "\n",
    "df_kl = pd.DataFrame(rows_kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving csv outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kw.sort_values([\"topic\",\"matched_keyword\",\"platform\",\"llm_label\"]).to_csv(SAVE_DIR/\"keyword_label_distribution.csv\", index=False)\n",
    "df_topic.sort_values([\"topic\",\"platform\",\"llm_label\"]).to_csv(SAVE_DIR/\"topic_label_distribution.csv\", index=False)\n",
    "align_kw.sort_values([\"topic\",\"matched_keyword\",\"platform\"]).to_csv(SAVE_DIR/\"alignment_rate_by_keyword.csv\", index=False)\n",
    "framing_dist.sort_values([\"topic\",\"framing_bucket\",\"platform\",\"llm_label\"]).to_csv(SAVE_DIR/\"framing_bucket_distributions.csv\", index=False)\n",
    "if not df_kl.empty:\n",
    "    df_kl.sort_values(\"kl_truth_vs_blue\", ascending=False).to_csv(SAVE_DIR/\"topic_kl_divergence_truth_vs_bluesky.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "top_kw = (df_kw.groupby([\"matched_keyword\"])[\"count\"].sum()\n",
    "        .sort_values(ascending=False).head(N).index.tolist())\n",
    "plot_kw = df_kw[df_kw[\"matched_keyword\"].isin(top_kw)]\n",
    "\n",
    "def stacked_bar(df, x_col, y_col=\"count\", hue_col=\"llm_label\", title=\"\", fname=\"plot.png\"):\n",
    "    # build wide format for stacked bar\n",
    "    wide = (df.pivot_table(index=x_col, columns=hue_col, values=y_col, aggfunc=\"sum\", fill_value=0)\n",
    "            .loc[:, [\"Left\",\"Right\",\"Neutral\"] if set([\"Left\",\"Right\",\"Neutral\"]).issubset(df[hue_col].unique()) else sorted(df[hue_col].unique())])\n",
    "    ax = wide.plot(kind=\"bar\", stacked=True, figsize=(12,6))\n",
    "    ax.set_xlabel(x_col.replace(\"_\",\" \"))\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    out = SAVE_DIR/fname\n",
    "    plt.savefig(out, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "stacked_bar(plot_kw, \"matched_keyword\",\n",
    "            title=\"Label distribution for top keywords (all platforms)\",\n",
    "            fname=\"top_keywords_stacked_labels.png\")\n",
    "\n",
    "# topic-level stacked bars by platform\n",
    "for plat in df_topic[\"platform\"].unique():\n",
    "    dfp = df_topic[df_topic[\"platform\"]==plat]\n",
    "    stacked_bar(dfp, \"topic\", y_col=\"count\",\n",
    "                title=f\"Topic label distribution — {plat}\",\n",
    "                fname=f\"topic_labels_{plat}.png\")\n",
    "\n",
    "# framing-bucket label distributions\n",
    "for plat in df_kw[\"platform\"].unique():\n",
    "    dfp = framing_dist[framing_dist[\"platform\"]==plat]\n",
    "    stacked_bar(dfp, \"framing_bucket\", y_col=\"count\",\n",
    "                title=f\"Framing-bucket label distribution — {plat}\",\n",
    "                fname=f\"framing_bucket_labels_{plat}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
