{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, gzip, io, random\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "DATA_DIRS = [\n",
    "    \"./bluesky/dataset/bluesky_with_noisy_labels.json\",\n",
    "    \"./truthsocial/dataset/truthsocial_with_noisy_labels.json\",\n",
    "]\n",
    "\n",
    "LABELS_LLM = [\"Left\",\"Right\",\"Neutral\"]\n",
    "LABELS_NOISY = [\"Left\", \"Right\"]\n",
    "LABEL2ID_LLM = {k:i for i,k in enumerate(LABELS_LLM)}\n",
    "ID2LABEL_LLM = {v:k for k,v in LABEL2ID_LLM.items()}\n",
    "LABEL2ID_NOISY = {k:i for i,k in enumerate(LABELS_NOISY)}\n",
    "ID2LABEL_NOISY = {v:k for k,v in LABEL2ID_NOISY.items()}\n",
    "\n",
    "def _open_text(path: Path):\n",
    "    if str(path).endswith(\".gz\"):\n",
    "        return io.TextIOWrapper(gzip.open(path, \"rb\"), encoding=\"utf-8\", errors=\"ignore\")\n",
    "    return open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def _iter_paths(root: Path):\n",
    "    ok = (\".json\",\".jsonl\",\".ndjson\",\".json.gz\",\".jsonl.gz\",\".ndjson.gz\")\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if any(\"\".join(p.suffixes).lower().endswith(ext) for ext in ok):\n",
    "            yield p\n",
    "\n",
    "def _iter_records(path: Path):\n",
    "    with _open_text(path) as f:\n",
    "        head = f.read(2048)\n",
    "        f.seek(0)\n",
    "        first = head.lstrip()[:1]\n",
    "        if first == \"[\":\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    for x in data:\n",
    "                        if isinstance(x, dict): yield x\n",
    "                elif isinstance(data, dict):\n",
    "                    yield data\n",
    "            except Exception:\n",
    "                for line in f:\n",
    "                    line=line.strip()\n",
    "                    if not line: continue\n",
    "                    try:\n",
    "                        x=json.loads(line)\n",
    "                        if isinstance(x, dict): yield x\n",
    "                    except: pass\n",
    "        else:\n",
    "            for line in f:\n",
    "                line=line.strip()\n",
    "                if not line: continue\n",
    "                try:\n",
    "                    x=json.loads(line)\n",
    "                    if isinstance(x, dict): yield x\n",
    "                except: pass\n",
    "\n",
    "def _clean_text(html_content):\n",
    "    \"\"\"\n",
    "    Strips all HTML tags and unescapes entities from a string.\n",
    "    \"\"\"\n",
    "    if not html_content or not isinstance(html_content, str):\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    text_with_entities = soup.get_text(separator=\" \", strip=True)\n",
    "    clean_text = html.unescape(text_with_entities)\n",
    "    return clean_text or None\n",
    "\n",
    "def _extract_text(rec: dict) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Heuristics across Bluesky/TruthSocial scrapes.\n",
    "    Try your common fields here; add more if needed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Bluesky record style:\n",
    "    if \"record\" in rec:\n",
    "        record = rec.get(\"record\") or {}\n",
    "        text = record.get(\"text\")\n",
    "        if isinstance(text, str) and text.strip():\n",
    "            return text.strip()\n",
    "        \n",
    "    # Truth social:\n",
    "    if \"content\" in rec:\n",
    "        cleaned = _clean_text(rec.get(\"content\"))\n",
    "        if cleaned:\n",
    "            return cleaned\n",
    "    \n",
    "    return None\n",
    "\n",
    "def load_dataframe(\n",
    "    roots: List[str],\n",
    "    min_len: int = 5,\n",
    "    include_topic_prefix: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    rows = []\n",
    "    \n",
    "    # 添加更详细的计数器\n",
    "    file_stats = {}\n",
    "    \n",
    "    for d in roots:\n",
    "        root = Path(d)\n",
    "        if not root.exists():\n",
    "            print(f\"[ERROR] File/Directory does not exist: {root}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {root}\")\n",
    "        print(f\"Exists: {root.exists()}\")\n",
    "        print(f\"Is file: {root.is_file()}\")\n",
    "        print(f\"File size: {root.stat().st_size if root.exists() else 'N/A'} bytes\")\n",
    "        \n",
    "        # 为每个文件初始化统计\n",
    "        file_key = str(root)\n",
    "        file_stats[file_key] = {\n",
    "            \"total_records\": 0,\n",
    "            \"valid_records\": 0,\n",
    "            \"skipped_no_label\": 0,\n",
    "            \"skipped_no_text\": 0,\n",
    "            \"platform_count\": {},\n",
    "            \"noisy_label_dist\": {\"left\": 0, \"right\": 0, \"other\": 0, \"none\": 0},\n",
    "            \"llm_label_dist\": {\"left\": 0, \"right\": 0, \"neutral\": 0, \"other\": 0}\n",
    "        }\n",
    "        \n",
    "        paths = [root] if root.is_file() else list(_iter_paths(root))\n",
    "        print(f\"Files to process: {len(paths)}\")\n",
    "        \n",
    "        for path in paths:\n",
    "            print(f\"  Processing file: {path}\")\n",
    "            record_count = 0\n",
    "            \n",
    "            try:\n",
    "                for rec in _iter_records(path):\n",
    "                    record_count += 1\n",
    "                    file_stats[file_key][\"total_records\"] += 1\n",
    "                    \n",
    "                    # 打印前几条记录的结构\n",
    "                    if record_count <= 2:\n",
    "                        print(f\"\\n    Record {record_count} structure:\")\n",
    "                        print(f\"      Top-level keys: {list(rec.keys())[:10]}\")  # 只显示前10个key\n",
    "                        if \"__meta__\" in rec:\n",
    "                            print(f\"      __meta__ keys: {list(rec.get('__meta__', {}).keys())}\")\n",
    "                        print(f\"      noisy_label: {rec.get('noisy_label')}\")\n",
    "                        if \"__meta__\" in rec:\n",
    "                            print(f\"      platform: {rec.get('__meta__', {}).get('platform')}\")\n",
    "                            print(f\"      llm_label: {rec.get('__meta__', {}).get('llm_label')}\")\n",
    "                    \n",
    "                    meta = rec.get(\"__meta__\", {}) or {}\n",
    "                    platform = (meta.get(\"platform\") or \"\").lower()\n",
    "                    \n",
    "                    # 统计平台\n",
    "                    if platform:\n",
    "                        file_stats[file_key][\"platform_count\"][platform] = \\\n",
    "                            file_stats[file_key][\"platform_count\"].get(platform, 0) + 1\n",
    "                    \n",
    "                    # ====== 规范化 LLM label ======\n",
    "                    raw_llm = meta.get(\"llm_label\")\n",
    "                    llm_label = None\n",
    "                    if isinstance(raw_llm, str):\n",
    "                        s = raw_llm.strip().lower()\n",
    "                        if s in [\"left\", \"right\", \"neutral\"]:\n",
    "                            file_stats[file_key][\"llm_label_dist\"][s] += 1\n",
    "                            mapping_llm = {\n",
    "                                \"left\": \"Left\",\n",
    "                                \"right\": \"Right\",\n",
    "                                \"neutral\": \"Neutral\",\n",
    "                            }\n",
    "                            llm_label = mapping_llm.get(s)\n",
    "                        else:\n",
    "                            file_stats[file_key][\"llm_label_dist\"][\"other\"] += 1\n",
    "                    \n",
    "                    # ====== 调试 noisy_label ======\n",
    "                    raw_noisy = rec.get(\"noisy_label\")\n",
    "                    if raw_noisy is None:\n",
    "                        file_stats[file_key][\"noisy_label_dist\"][\"none\"] += 1\n",
    "                    elif isinstance(raw_noisy, str):\n",
    "                        s = raw_noisy.strip().lower()\n",
    "                        if s in [\"left\", \"right\"]:\n",
    "                            file_stats[file_key][\"noisy_label_dist\"][s] += 1\n",
    "                        else:\n",
    "                            file_stats[file_key][\"noisy_label_dist\"][\"other\"] += 1\n",
    "                    \n",
    "                    # ====== 规范化 noisy label ======\n",
    "                    noisy_label = None\n",
    "                    if isinstance(raw_noisy, str):\n",
    "                        s = raw_noisy.strip().lower()\n",
    "                        mapping_noisy = {\n",
    "                            \"left\": \"Left\",\n",
    "                            \"right\": \"Right\",\n",
    "                        }\n",
    "                        noisy_label = mapping_noisy.get(s)\n",
    "                    \n",
    "                    # 检查标签\n",
    "                    if llm_label not in LABELS_LLM or noisy_label not in LABELS_NOISY:\n",
    "                        file_stats[file_key][\"skipped_no_label\"] += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # ====== 文本抽取与清洗 ======\n",
    "                    txt = _extract_text(rec)\n",
    "                    if not txt or len(txt) < min_len:\n",
    "                        file_stats[file_key][\"skipped_no_text\"] += 1\n",
    "                        continue\n",
    "                    \n",
    "                    file_stats[file_key][\"valid_records\"] += 1\n",
    "                    \n",
    "                    topic = meta.get(\"topic\") or \"\"\n",
    "                    if include_topic_prefix and topic:\n",
    "                        txt = f\"Topic: {topic}. Post: {txt}\"\n",
    "                    \n",
    "                    matched_keyword = meta.get(\"matched_keyword\") or \"\"\n",
    "                    \n",
    "                    author_did = \"\"\n",
    "                    if platform == \"bluesky\":\n",
    "                        author = rec.get(\"author\") or {}\n",
    "                        did = author.get(\"did\")\n",
    "                        if did:\n",
    "                            author_did = f\"bsky:{did}\"\n",
    "                    elif platform == \"truthsocial\":\n",
    "                        account = rec.get(\"account\") or {}\n",
    "                        acc_id = account.get(\"id\")\n",
    "                        if acc_id:\n",
    "                            author_did = f\"truth:{acc_id}\"\n",
    "                    \n",
    "                    post_id = rec.get(\"id\") or rec.get(\"cid\") or \"\"\n",
    "                    \n",
    "                    rows.append({\n",
    "                        \"text\": txt,\n",
    "                        \"llm_label\": llm_label,\n",
    "                        \"noisy_label\": noisy_label,\n",
    "                        \"topic\": topic,\n",
    "                        \"platform\": platform,\n",
    "                        \"matched_keyword\": matched_keyword,\n",
    "                        \"author_did\": author_did,\n",
    "                        \"post_id\": post_id,\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  [ERROR] Failed to process file {path}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "            \n",
    "            print(f\"    Processed {record_count} records from this file\")\n",
    "    \n",
    "    # 打印详细统计\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"=== Detailed File Statistics ===\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for file_key, stats in file_stats.items():\n",
    "        print(f\"\\nFile: {file_key}\")\n",
    "        print(f\"  Total records: {stats['total_records']}\")\n",
    "        print(f\"  Valid records kept: {stats['valid_records']}\")\n",
    "        print(f\"  Skipped (no valid labels): {stats['skipped_no_label']}\")\n",
    "        print(f\"  Skipped (no text): {stats['skipped_no_text']}\")\n",
    "        print(f\"  Platforms: {stats['platform_count']}\")\n",
    "        print(f\"  Noisy label distribution: {stats['noisy_label_dist']}\")\n",
    "        print(f\"  LLM label distribution: {stats['llm_label_dist']}\")\n",
    "    \n",
    "    df = pd.DataFrame(rows).drop_duplicates(subset=[\"text\", \"post_id\"], keep=\"first\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"=== Final DataFrame Summary ===\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total rows after deduplication: {len(df)}\")\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        print(\"\\n=== Platform vs Noisy Label ===\")\n",
    "        print(pd.crosstab(df[\"platform\"], df[\"noisy_label\"], margins=True))\n",
    "        \n",
    "        print(\"\\n=== Platform Distribution ===\")\n",
    "        print(df[\"platform\"].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def stratified_splits(df: pd.DataFrame, test_size=0.2, val_size=0.1, group_col: Optional[str]=None, seed=RANDOM_SEED):\n",
    "    \"\"\"\n",
    "    Returns df_train, df_val, df_test.\n",
    "    If group_col is provided (e.g., 'author_did' or 'platform'), we avoid leakage by grouping.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "\n",
    "    if group_col and group_col in df.columns and df[group_col].astype(bool).any():\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "        idx = np.arange(len(df))\n",
    "        train_idx, test_idx = next(gss.split(idx, groups=df[group_col]))\n",
    "        df_train_full, df_test = df.iloc[train_idx], df.iloc[test_idx]\n",
    "\n",
    "        # val from train_full\n",
    "        gss2 = GroupShuffleSplit(n_splits=1, test_size=val_size/(1.0-test_size), random_state=seed)\n",
    "        idx2 = np.arange(len(df_train_full))\n",
    "        tr_idx, val_idx = next(gss2.split(idx2, groups=df_train_full[group_col].values))\n",
    "        df_train, df_val = df_train_full.iloc[tr_idx], df_train_full.iloc[val_idx]\n",
    "    else:\n",
    "        df_train_full, df_test = train_test_split(\n",
    "            df, test_size=test_size, random_state=seed, stratify=df[\"y\"]\n",
    "        )\n",
    "        df_train, df_val = train_test_split(\n",
    "            df_train_full, test_size=val_size/(1.0-test_size), random_state=seed, stratify=df_train_full[\"y\"]\n",
    "        )\n",
    "    \n",
    "    print(\"\\n=== Split Statistics ===\")    \n",
    "    for name, part in [(\"train\", df_train), (\"val\", df_val), (\"test\", df_test)]:\n",
    "        print(f\"\\n{name.upper()}: shape={part.shape}\")\n",
    "        print(f\"  LLM labels: {part['llm_label'].value_counts().to_dict()}\")\n",
    "        print(f\"  Noisy labels: {part['noisy_label'].value_counts().to_dict()}\")\n",
    "\n",
    "    return df_train.reset_index(drop=True), df_val.reset_index(drop=True), df_test.reset_index(drop=True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: bluesky/dataset/bluesky_with_noisy_labels.json\n",
      "Exists: True\n",
      "Is file: True\n",
      "File size: 431365692 bytes\n",
      "Files to process: 1\n",
      "  Processing file: bluesky/dataset/bluesky_with_noisy_labels.json\n",
      "\n",
      "    Record 1 structure:\n",
      "      Top-level keys: ['author', 'cid', 'indexed_at', 'record', 'uri', 'embed', 'labels', 'like_count', 'quote_count', 'reply_count']\n",
      "      __meta__ keys: ['platform', 'topic', 'framing', 'matched_keyword', 'llm_label']\n",
      "      noisy_label: left\n",
      "      platform: bluesky\n",
      "      llm_label: Left\n",
      "\n",
      "    Record 2 structure:\n",
      "      Top-level keys: ['author', 'cid', 'indexed_at', 'record', 'uri', 'embed', 'labels', 'like_count', 'quote_count', 'reply_count']\n",
      "      __meta__ keys: ['platform', 'topic', 'framing', 'matched_keyword', 'llm_label']\n",
      "      noisy_label: left\n",
      "      platform: bluesky\n",
      "      llm_label: Neutral\n",
      "    Processed 94264 records from this file\n",
      "\n",
      "============================================================\n",
      "Processing: truthsocial/dataset/truthsocial_with_noisy_labels.json\n",
      "Exists: True\n",
      "Is file: True\n",
      "File size: 298493511 bytes\n",
      "Files to process: 1\n",
      "  Processing file: truthsocial/dataset/truthsocial_with_noisy_labels.json\n",
      "\n",
      "    Record 1 structure:\n",
      "      Top-level keys: ['created_at', 'edited_at', 'spoiler_text', 'language', 'id', 'in_reply_to_id', 'in_reply_to_account_id', 'sensitive', 'visibility', 'uri']\n",
      "      __meta__ keys: ['topic', 'matched_keyword', 'platform', 'source_folder', 'source_date', 'llm_label']\n",
      "      noisy_label: right\n",
      "      platform: truthsocial\n",
      "      llm_label: Right\n",
      "\n",
      "    Record 2 structure:\n",
      "      Top-level keys: ['created_at', 'edited_at', 'spoiler_text', 'language', 'id', 'in_reply_to_id', 'in_reply_to_account_id', 'sensitive', 'visibility', 'uri']\n",
      "      __meta__ keys: ['topic', 'matched_keyword', 'platform', 'source_folder', 'source_date', 'llm_label']\n",
      "      noisy_label: right\n",
      "      platform: truthsocial\n",
      "      llm_label: Right\n",
      "    Processed 38195 records from this file\n",
      "\n",
      "============================================================\n",
      "=== Detailed File Statistics ===\n",
      "============================================================\n",
      "\n",
      "File: bluesky/dataset/bluesky_with_noisy_labels.json\n",
      "  Total records: 94264\n",
      "  Valid records kept: 94230\n",
      "  Skipped (no valid labels): 0\n",
      "  Skipped (no text): 34\n",
      "  Platforms: {'bluesky': 94264}\n",
      "  Noisy label distribution: {'left': 94264, 'right': 0, 'other': 0, 'none': 0}\n",
      "  LLM label distribution: {'left': 41748, 'right': 10651, 'neutral': 41865, 'other': 0}\n",
      "\n",
      "File: truthsocial/dataset/truthsocial_with_noisy_labels.json\n",
      "  Total records: 38195\n",
      "  Valid records kept: 38190\n",
      "  Skipped (no valid labels): 1\n",
      "  Skipped (no text): 4\n",
      "  Platforms: {'truthsocial': 38195}\n",
      "  Noisy label distribution: {'left': 0, 'right': 38195, 'other': 0, 'none': 0}\n",
      "  LLM label distribution: {'left': 2910, 'right': 23131, 'neutral': 12153, 'other': 1}\n",
      "\n",
      "============================================================\n",
      "=== Final DataFrame Summary ===\n",
      "============================================================\n",
      "Total rows after deduplication: 131770\n",
      "\n",
      "=== Platform vs Noisy Label ===\n",
      "noisy_label   Left  Right     All\n",
      "platform                         \n",
      "bluesky      93580      0   93580\n",
      "truthsocial      0  38190   38190\n",
      "All          93580  38190  131770\n",
      "\n",
      "=== Platform Distribution ===\n",
      "platform\n",
      "bluesky        93580\n",
      "truthsocial    38190\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Split Statistics ===\n",
      "\n",
      "TRAIN: shape=(92239, 9)\n",
      "  LLM labels: {'Neutral': 37623, 'Left': 31032, 'Right': 23584}\n",
      "  Noisy labels: {'Left': 65503, 'Right': 26736}\n",
      "\n",
      "VAL: shape=(13177, 9)\n",
      "  LLM labels: {'Neutral': 5375, 'Left': 4433, 'Right': 3369}\n",
      "  Noisy labels: {'Left': 9416, 'Right': 3761}\n",
      "\n",
      "TEST: shape=(26354, 9)\n",
      "  LLM labels: {'Neutral': 10749, 'Left': 8867, 'Right': 6738}\n",
      "  Noisy labels: {'Left': 18661, 'Right': 7693}\n",
      "\n",
      "==================================================\n",
      "=== Final Summary ===\n",
      "==================================================\n",
      "Train: 92239\n",
      "Val: 13177\n",
      "Test: 26354\n"
     ]
    }
   ],
   "source": [
    "df_all = load_dataframe(DATA_DIRS)\n",
    "\n",
    "# 2. 保险过滤一下（理论上 load_dataframe 已经做了）\n",
    "df_all = df_all[\n",
    "    df_all[\"llm_label\"].isin(LABELS_LLM) &\n",
    "    df_all[\"noisy_label\"].isin(LABELS_NOISY)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# 3. 用 LLM 标签做 stratify basis\n",
    "df_all[\"y\"] = df_all[\"llm_label\"].map(LABEL2ID_LLM)\n",
    "\n",
    "df_train, df_val, df_test = stratified_splits(\n",
    "    df_all,\n",
    "    test_size=0.2,\n",
    "    val_size=0.1,\n",
    "    group_col=None,   # 或 None，看你需不需要 author 去重\n",
    "    seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== Final Summary ===\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Train: {len(df_train)}\")\n",
    "print(f\"Val: {len(df_val)}\")\n",
    "print(f\"Test: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: bluesky/dataset/bluesky_with_noisy_labels.json\n",
      "Exists: True\n",
      "Is file: True\n",
      "File size: 431365692 bytes\n",
      "Files to process: 1\n",
      "  Processing file: bluesky/dataset/bluesky_with_noisy_labels.json\n",
      "\n",
      "    Record 1 structure:\n",
      "      Top-level keys: ['author', 'cid', 'indexed_at', 'record', 'uri', 'embed', 'labels', 'like_count', 'quote_count', 'reply_count']\n",
      "      __meta__ keys: ['platform', 'topic', 'framing', 'matched_keyword', 'llm_label']\n",
      "      noisy_label: left\n",
      "      platform: bluesky\n",
      "      llm_label: Left\n",
      "\n",
      "    Record 2 structure:\n",
      "      Top-level keys: ['author', 'cid', 'indexed_at', 'record', 'uri', 'embed', 'labels', 'like_count', 'quote_count', 'reply_count']\n",
      "      __meta__ keys: ['platform', 'topic', 'framing', 'matched_keyword', 'llm_label']\n",
      "      noisy_label: left\n",
      "      platform: bluesky\n",
      "      llm_label: Neutral\n",
      "    Processed 94264 records from this file\n",
      "\n",
      "============================================================\n",
      "Processing: truthsocial/dataset/truthsocial_with_noisy_labels.json\n",
      "Exists: True\n",
      "Is file: True\n",
      "File size: 298493511 bytes\n",
      "Files to process: 1\n",
      "  Processing file: truthsocial/dataset/truthsocial_with_noisy_labels.json\n",
      "\n",
      "    Record 1 structure:\n",
      "      Top-level keys: ['created_at', 'edited_at', 'spoiler_text', 'language', 'id', 'in_reply_to_id', 'in_reply_to_account_id', 'sensitive', 'visibility', 'uri']\n",
      "      __meta__ keys: ['topic', 'matched_keyword', 'platform', 'source_folder', 'source_date', 'llm_label']\n",
      "      noisy_label: right\n",
      "      platform: truthsocial\n",
      "      llm_label: Right\n",
      "\n",
      "    Record 2 structure:\n",
      "      Top-level keys: ['created_at', 'edited_at', 'spoiler_text', 'language', 'id', 'in_reply_to_id', 'in_reply_to_account_id', 'sensitive', 'visibility', 'uri']\n",
      "      __meta__ keys: ['topic', 'matched_keyword', 'platform', 'source_folder', 'source_date', 'llm_label']\n",
      "      noisy_label: right\n",
      "      platform: truthsocial\n",
      "      llm_label: Right\n",
      "    Processed 38195 records from this file\n",
      "\n",
      "============================================================\n",
      "=== Detailed File Statistics ===\n",
      "============================================================\n",
      "\n",
      "File: bluesky/dataset/bluesky_with_noisy_labels.json\n",
      "  Total records: 94264\n",
      "  Valid records kept: 94230\n",
      "  Skipped (no valid labels): 0\n",
      "  Skipped (no text): 34\n",
      "  Platforms: {'bluesky': 94264}\n",
      "  Noisy label distribution: {'left': 94264, 'right': 0, 'other': 0, 'none': 0}\n",
      "  LLM label distribution: {'left': 41748, 'right': 10651, 'neutral': 41865, 'other': 0}\n",
      "\n",
      "File: truthsocial/dataset/truthsocial_with_noisy_labels.json\n",
      "  Total records: 38195\n",
      "  Valid records kept: 38190\n",
      "  Skipped (no valid labels): 1\n",
      "  Skipped (no text): 4\n",
      "  Platforms: {'truthsocial': 38195}\n",
      "  Noisy label distribution: {'left': 0, 'right': 38195, 'other': 0, 'none': 0}\n",
      "  LLM label distribution: {'left': 2910, 'right': 23131, 'neutral': 12153, 'other': 1}\n",
      "\n",
      "============================================================\n",
      "=== Final DataFrame Summary ===\n",
      "============================================================\n",
      "Total rows after deduplication: 131770\n",
      "\n",
      "=== Platform vs Noisy Label ===\n",
      "noisy_label   Left  Right     All\n",
      "platform                         \n",
      "bluesky      93580      0   93580\n",
      "truthsocial      0  38190   38190\n",
      "All          93580  38190  131770\n",
      "\n",
      "=== Platform Distribution ===\n",
      "platform\n",
      "bluesky        93580\n",
      "truthsocial    38190\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Split Statistics ===\n",
      "\n",
      "TRAIN: shape=(92239, 9)\n",
      "  LLM labels: {'Neutral': 37623, 'Left': 31032, 'Right': 23584}\n",
      "  Noisy labels: {'Left': 65503, 'Right': 26736}\n",
      "\n",
      "VAL: shape=(13177, 9)\n",
      "  LLM labels: {'Neutral': 5375, 'Left': 4433, 'Right': 3369}\n",
      "  Noisy labels: {'Left': 9416, 'Right': 3761}\n",
      "\n",
      "TEST: shape=(26354, 9)\n",
      "  LLM labels: {'Neutral': 10749, 'Left': 8867, 'Right': 6738}\n",
      "  Noisy labels: {'Left': 18661, 'Right': 7693}\n",
      "\n",
      "Dataset sizes:\n",
      "Train: 92239\n",
      "Val: 13177\n",
      "Test: 26354\n",
      "\n",
      "============================================================\n",
      "Training llm_labels with llm_label\n",
      "============================================================\n",
      "\n",
      "Training label distribution:\n",
      "llm_label\n",
      "Neutral    37623\n",
      "Left       31032\n",
      "Right      23584\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Performing grid search...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params: {'nb__alpha': 0.3}\n",
      "Best Mean Cross-Validation F1 Score on train: 0.6816\n",
      "\n",
      "Validation Accuracy: 0.6879\n",
      "\n",
      "--- Test Set Results ---\n",
      "Test Accuracy: 0.6893\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left      0.616     0.788     0.692      8867\n",
      "       Right      0.721     0.649     0.683      6738\n",
      "     Neutral      0.760     0.633     0.691     10749\n",
      "\n",
      "    accuracy                          0.689     26354\n",
      "   macro avg      0.699     0.690     0.689     26354\n",
      "weighted avg      0.702     0.689     0.689     26354\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "Labels: ['Left', 'Right', 'Neutral']\n",
      "[[6991  603 1273]\n",
      " [1491 4371  876]\n",
      " [2858 1086 6805]]\n",
      "\n",
      "Model saved to: models_nb/llm_labels/nb_tfidf.joblib\n",
      "Labels saved to: models_nb/llm_labels/labels.txt\n",
      "Results saved to: models_nb/llm_labels/results.json\n",
      "\n",
      "============================================================\n",
      "Training noisy_labels with noisy_label\n",
      "============================================================\n",
      "\n",
      "Training label distribution:\n",
      "noisy_label\n",
      "Left     65503\n",
      "Right    26736\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Performing grid search...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best params: {'nb__alpha': 0.1}\n",
      "Best Mean Cross-Validation F1 Score on train: 0.8641\n",
      "\n",
      "Validation Accuracy: 0.8975\n",
      "\n",
      "--- Test Set Results ---\n",
      "Test Accuracy: 0.8985\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left      0.910     0.951     0.930     18661\n",
      "       Right      0.867     0.771     0.816      7693\n",
      "\n",
      "    accuracy                          0.898     26354\n",
      "   macro avg      0.888     0.861     0.873     26354\n",
      "weighted avg      0.897     0.898     0.897     26354\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "Labels: ['Left', 'Right']\n",
      "[[17750   911]\n",
      " [ 1764  5929]]\n",
      "\n",
      "Model saved to: models_nb/noisy_labels/nb_tfidf.joblib\n",
      "Labels saved to: models_nb/noisy_labels/labels.txt\n",
      "Results saved to: models_nb/noisy_labels/results.json\n",
      "\n",
      "============================================================\n",
      "Model Comparison\n",
      "============================================================\n",
      "       Model  Best Alpha  CV F1 Score  Val Accuracy  Test Accuracy\n",
      "  LLM Labels         0.3     0.681632      0.687865       0.689345\n",
      "Noisy Labels         0.1     0.864068      0.897549       0.898497\n",
      "\n",
      "============================================================\n",
      "Noisy Label Analysis\n",
      "============================================================\n",
      "\n",
      "Crosstab: LLM Label vs Noisy Label (in test set):\n",
      "noisy_label   Left  Right    All\n",
      "llm_label                       \n",
      "Left          8307    560   8867\n",
      "Neutral       8318   2431  10749\n",
      "Right         2036   4702   6738\n",
      "All          18661   7693  26354\n",
      "\n",
      "Noisy model accuracy on LLM=Left subset: 0.9408 (n=8867)\n",
      "\n",
      "Noisy model accuracy on LLM=Right subset: 0.8221 (n=6738)\n",
      "\n",
      "Noisy model accuracy on LLM=Neutral subset: 0.9115 (n=10749)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# 假设你已经运行了之前的数据加载代码，得到了 df_train, df_val, df_test\n",
    "\n",
    "def train_and_evaluate_nb(df_train, df_val, df_test, label_col, labels_list, model_name):\n",
    "    \"\"\"\n",
    "    训练和评估 Naive Bayes 模型\n",
    "    \n",
    "    参数:\n",
    "    - df_train: 训练数据\n",
    "    - df_val: 验证数据\n",
    "    - df_test: 测试数据\n",
    "    - label_col: 标签列名 ('llm_label' 或 'noisy_label')\n",
    "    - labels_list: 标签列表 (LABELS_LLM 或 LABELS_NOISY)\n",
    "    - model_name: 模型名称（用于保存）\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name} with {label_col}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 准备数据\n",
    "    X_train = df_train[\"text\"]\n",
    "    y_train = df_train[label_col]\n",
    "    X_val = df_val[\"text\"]\n",
    "    y_val = df_val[label_col]\n",
    "    X_test = df_test[\"text\"]\n",
    "    y_test = df_test[label_col]\n",
    "    \n",
    "    # 打印标签分布\n",
    "    print(f\"\\nTraining label distribution:\")\n",
    "    print(y_train.value_counts())\n",
    "    \n",
    "    # 创建 pipeline\n",
    "    pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=5,\n",
    "            max_df=0.7,\n",
    "            strip_accents=\"unicode\",\n",
    "            sublinear_tf=True,\n",
    "            token_pattern=r\"[A-Za-z][A-Za-z0-9_\\-']+\"\n",
    "        )),\n",
    "        (\"nb\", ComplementNB())\n",
    "    ])\n",
    "    \n",
    "    # Grid search\n",
    "    param_grid = {\"nb__alpha\": [0.1, 0.3, 0.5, 1.0]}\n",
    "    gs = GridSearchCV(\n",
    "        pipe, \n",
    "        param_grid, \n",
    "        scoring=\"f1_macro\", \n",
    "        cv=3, \n",
    "        n_jobs=-1, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nPerforming grid search...\")\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best params: {gs.best_params_}\")\n",
    "    print(f\"Best Mean Cross-Validation F1 Score on train: {gs.best_score_:.4f}\")\n",
    "    \n",
    "    # 在验证集上评估\n",
    "    best_model = gs.best_estimator_\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"\\nValidation Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # 在测试集上评估\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"\\n--- Test Set Results ---\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred, labels=labels_list, digits=3))\n",
    "    \n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_test_pred, labels=labels_list)\n",
    "    print(f\"Labels: {labels_list}\")\n",
    "    print(cm)\n",
    "    \n",
    "    # 保存模型\n",
    "    os.makedirs(f\"models_nb/{model_name}\", exist_ok=True)\n",
    "    model_path = f\"models_nb/{model_name}/nb_tfidf.joblib\"\n",
    "    joblib.dump(best_model, model_path)\n",
    "    \n",
    "    # 保存标签\n",
    "    labels_path = f\"models_nb/{model_name}/labels.txt\"\n",
    "    with open(labels_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(labels_list))\n",
    "    \n",
    "    # 保存结果\n",
    "    results = {\n",
    "        \"model_name\": model_name,\n",
    "        \"label_col\": label_col,\n",
    "        \"best_params\": gs.best_params_,\n",
    "        \"best_cv_score\": float(gs.best_score_),\n",
    "        \"val_accuracy\": float(val_acc),\n",
    "        \"test_accuracy\": float(test_acc),\n",
    "        \"test_predictions\": {\n",
    "            \"y_true\": y_test.tolist(),\n",
    "            \"y_pred\": y_test_pred.tolist()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results_path = f\"models_nb/{model_name}/results.json\"\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nModel saved to: {model_path}\")\n",
    "    print(f\"Labels saved to: {labels_path}\")\n",
    "    print(f\"Results saved to: {results_path}\")\n",
    "    \n",
    "    return best_model, results\n",
    "\n",
    "def compare_models(results_llm, results_noisy):\n",
    "    \"\"\"比较两个模型的性能\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Model Comparison\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        \"Model\": [\"LLM Labels\", \"Noisy Labels\"],\n",
    "        \"Best Alpha\": [results_llm[\"best_params\"][\"nb__alpha\"], \n",
    "                      results_noisy[\"best_params\"][\"nb__alpha\"]],\n",
    "        \"CV F1 Score\": [results_llm[\"best_cv_score\"], \n",
    "                       results_noisy[\"best_cv_score\"]],\n",
    "        \"Val Accuracy\": [results_llm[\"val_accuracy\"], \n",
    "                        results_noisy[\"val_accuracy\"]],\n",
    "        \"Test Accuracy\": [results_llm[\"test_accuracy\"], \n",
    "                         results_noisy[\"test_accuracy\"]]\n",
    "    })\n",
    "    \n",
    "    print(comparison.to_string(index=False))\n",
    "    \n",
    "    # 计算两个模型预测的一致性（仅适用于二分类）\n",
    "    if len(LABELS_LLM) == 2 and len(LABELS_NOISY) == 2:\n",
    "        y_pred_llm = results_llm[\"test_predictions\"][\"y_pred\"]\n",
    "        y_pred_noisy = results_noisy[\"test_predictions\"][\"y_pred\"]\n",
    "        \n",
    "        # 如果标签集相同，可以直接比较\n",
    "        if set(LABELS_LLM) == set(LABELS_NOISY):\n",
    "            agreement = sum(1 for a, b in zip(y_pred_llm, y_pred_noisy) if a == b)\n",
    "            agreement_rate = agreement / len(y_pred_llm)\n",
    "            print(f\"\\nPrediction Agreement Rate: {agreement_rate:.4f}\")\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    # 确保已经加载了数据\n",
    "    # 这里假设你已经运行了之前的代码得到了 df_train, df_val, df_test\n",
    "    \n",
    "    # 加载数据（如果还没有加载）\n",
    "    df_all = load_dataframe(DATA_DIRS)\n",
    "    \n",
    "    # 过滤\n",
    "    df_all = df_all[\n",
    "        df_all[\"llm_label\"].isin(LABELS_LLM) &\n",
    "        df_all[\"noisy_label\"].isin(LABELS_NOISY)\n",
    "    ].reset_index(drop=True)\n",
    "    \n",
    "    # 用 LLM 标签做 stratify（确保相同的数据划分）\n",
    "    df_all[\"y\"] = df_all[\"llm_label\"].map(LABEL2ID_LLM)\n",
    "    \n",
    "    # 划分数据集（这确保了两个模型使用完全相同的训练/验证/测试集）\n",
    "    df_train, df_val, df_test = stratified_splits(\n",
    "        df_all,\n",
    "        test_size=0.2,\n",
    "        val_size=0.1,\n",
    "        group_col=None,\n",
    "        seed=RANDOM_SEED,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDataset sizes:\")\n",
    "    print(f\"Train: {len(df_train)}\")\n",
    "    print(f\"Val: {len(df_val)}\")\n",
    "    print(f\"Test: {len(df_test)}\")\n",
    "    \n",
    "    # 训练 LLM 标签模型\n",
    "    model_llm, results_llm = train_and_evaluate_nb(\n",
    "        df_train, df_val, df_test,\n",
    "        label_col=\"llm_label\",\n",
    "        labels_list=LABELS_LLM,\n",
    "        model_name=\"llm_labels\"\n",
    "    )\n",
    "    \n",
    "    # 训练 Noisy 标签模型\n",
    "    model_noisy, results_noisy = train_and_evaluate_nb(\n",
    "        df_train, df_val, df_test,\n",
    "        label_col=\"noisy_label\",\n",
    "        labels_list=LABELS_NOISY,\n",
    "        model_name=\"noisy_labels\"\n",
    "    )\n",
    "    \n",
    "    # 比较两个模型\n",
    "    compare_models(results_llm, results_noisy)\n",
    "    \n",
    "    # 额外分析：查看 noisy label 的分布情况\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Noisy Label Analysis\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 查看不同 LLM 标签下的 noisy label 分布\n",
    "    print(\"\\nCrosstab: LLM Label vs Noisy Label (in test set):\")\n",
    "    print(pd.crosstab(df_test[\"llm_label\"], df_test[\"noisy_label\"], margins=True))\n",
    "    \n",
    "    # 如果你想看看模型在不同子集上的表现\n",
    "    for llm_label in LABELS_LLM:\n",
    "        subset = df_test[df_test[\"llm_label\"] == llm_label]\n",
    "        if len(subset) > 0:\n",
    "            # 对于 noisy label 模型的预测\n",
    "            y_true_subset = subset[\"noisy_label\"]\n",
    "            X_subset = subset[\"text\"]\n",
    "            y_pred_subset = model_noisy.predict(X_subset)\n",
    "            acc = accuracy_score(y_true_subset, y_pred_subset)\n",
    "            print(f\"\\nNoisy model accuracy on LLM={llm_label} subset: {acc:.4f} (n={len(subset)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Task Comparison\n",
      "============================================================\n",
      "\n",
      "Task 1 - Platform Classification (Noisy Labels):\n",
      "  - Binary classification: Bluesky vs TruthSocial\n",
      "  - What model learns: Platform-specific writing styles, topics, vocabulary\n",
      "  - Accuracy: 89.85%\n",
      "\n",
      "Task 2 - Political Stance Detection (LLM Labels):\n",
      "  - 3-way classification: Left vs Right vs Neutral\n",
      "  - What model learns: Actual political ideology from content\n",
      "  - Accuracy: 68.93%\n",
      "\n",
      "============================================================\n",
      "Actual Political Diversity in Each Platform\n",
      "============================================================\n",
      "\n",
      "BLUESKY (n=18661):\n",
      "  Neutral: 44.6%\n",
      "  Left: 44.5%\n",
      "  Right: 10.9%\n",
      "\n",
      "TRUTHSOCIAL (n=7693):\n",
      "  Right: 61.1%\n",
      "  Neutral: 31.6%\n",
      "  Left: 7.3%\n"
     ]
    }
   ],
   "source": [
    "# 让我们明确地比较这两个任务\n",
    "print(\"=\"*60)\n",
    "print(\"Task Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTask 1 - Platform Classification (Noisy Labels):\")\n",
    "print(\"  - Binary classification: Bluesky vs TruthSocial\")\n",
    "print(\"  - What model learns: Platform-specific writing styles, topics, vocabulary\")\n",
    "print(\"  - Accuracy: 89.85%\")\n",
    "\n",
    "print(\"\\nTask 2 - Political Stance Detection (LLM Labels):\")\n",
    "print(\"  - 3-way classification: Left vs Right vs Neutral\")\n",
    "print(\"  - What model learns: Actual political ideology from content\")\n",
    "print(\"  - Accuracy: 68.93%\")\n",
    "\n",
    "# 查看实际的政治多样性\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Actual Political Diversity in Each Platform\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for platform in ['bluesky', 'truthsocial']:\n",
    "    subset = df_test[df_test['platform'] == platform]\n",
    "    print(f\"\\n{platform.upper()} (n={len(subset)}):\")\n",
    "    distribution = subset['llm_label'].value_counts(normalize=True)\n",
    "    for label, pct in distribution.items():\n",
    "        print(f\"  {label}: {pct:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Platform Assumption Analysis\n",
      "============================================================\n",
      "\n",
      "Platform assumption accuracy (excluding Neutral):\n",
      "  Correct: 13009/15605 = 83.4%\n",
      "\n",
      "Bluesky users actually Left-leaning: 80.3%\n",
      "TruthSocial users actually Right-leaning: 89.4%\n"
     ]
    }
   ],
   "source": [
    "# 分析平台假设的准确性\n",
    "print(\"=\"*60)\n",
    "print(\"Platform Assumption Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 计算\"平台假设\"的准确率（如果用平台预测真实政治倾向）\n",
    "df_test['platform_assumption'] = df_test['platform'].map({\n",
    "    'bluesky': 'Left',\n",
    "    'truthsocial': 'Right'\n",
    "})\n",
    "\n",
    "# 只看 Left 和 Right（排除 Neutral）\n",
    "df_binary = df_test[df_test['llm_label'].isin(['Left', 'Right'])]\n",
    "\n",
    "correct_assumption = (df_binary['platform_assumption'] == df_binary['llm_label']).sum()\n",
    "total_binary = len(df_binary)\n",
    "\n",
    "print(f\"\\nPlatform assumption accuracy (excluding Neutral):\")\n",
    "print(f\"  Correct: {correct_assumption}/{total_binary} = {correct_assumption/total_binary:.1%}\")\n",
    "\n",
    "# 分别看每个平台\n",
    "for platform in ['bluesky', 'truthsocial']:\n",
    "    platform_binary = df_binary[df_binary['platform'] == platform]\n",
    "    if platform == 'bluesky':\n",
    "        accuracy = (platform_binary['llm_label'] == 'Left').mean()\n",
    "        print(f\"\\nBluesky users actually Left-leaning: {accuracy:.1%}\")\n",
    "    else:\n",
    "        accuracy = (platform_binary['llm_label'] == 'Right').mean()\n",
    "        print(f\"TruthSocial users actually Right-leaning: {accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Platform-Specific Features Learned by Model\n",
      "============================================================\n",
      "\n",
      "Top features for 'Left' (actually Bluesky):\n",
      "  job creators\n",
      "  fuck\n",
      "  fucking\n",
      "  from ecosearch\n",
      "  asshole\n",
      "  lgbtqnation com\n",
      "  together scantopray\n",
      "  lgbtqnation\n",
      "  see medicare\n",
      "  today www\n",
      "\n",
      "Top features for 'Right' (actually TruthSocial):\n",
      "  com users\n",
      "  statuses\n",
      "  rt https\n",
      "  national intelligence\n",
      "  presssec\n",
      "  policy immigration\n",
      "  pardons were\n",
      "  pardons to\n",
      "  administration mark\n",
      "  report were\n"
     ]
    }
   ],
   "source": [
    "# 提取模型学到的特征\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 使用训练好的 noisy label 模型\n",
    "vectorizer = model_noisy.named_steps['tfidf']\n",
    "classifier = model_noisy.named_steps['nb']\n",
    "\n",
    "# 获取特征重要性\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_log_prob = classifier.feature_log_prob_\n",
    "\n",
    "# 找出区分两个平台的关键词\n",
    "print(\"=\"*60)\n",
    "print(\"Platform-Specific Features Learned by Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Left (Bluesky) 的特征词\n",
    "left_scores = feature_log_prob[0]  # Left class\n",
    "top_left_indices = left_scores.argsort()[-20:][::-1]\n",
    "print(\"\\nTop features for 'Left' (actually Bluesky):\")\n",
    "for idx in top_left_indices[:10]:\n",
    "    print(f\"  {feature_names[idx]}\")\n",
    "\n",
    "# Right (TruthSocial) 的特征词\n",
    "right_scores = feature_log_prob[1]  # Right class\n",
    "top_right_indices = right_scores.argsort()[-20:][::-1]\n",
    "print(\"\\nTop features for 'Right' (actually TruthSocial):\")\n",
    "for idx in top_right_indices[:10]:\n",
    "    print(f\"  {feature_names[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Meaningful Analysis: Platform-Politics Correlation\n",
      "============================================================\n",
      "Matthews Correlation Coefficient: 0.665\n",
      "(1.0 = perfect correlation, 0 = no correlation, -1.0 = perfect inverse correlation)\n",
      "\n",
      "Conditional Probabilities:\n",
      "P(Left | bluesky): 0.445\n",
      "P(Right | bluesky): 0.109\n",
      "P(Left | truthsocial): 0.073\n",
      "P(Right | truthsocial): 0.611\n"
     ]
    }
   ],
   "source": [
    "# 更有意义的分析\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Meaningful Analysis: Platform-Politics Correlation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 计算平台选择与政治倾向的相关性\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# 只看二分类情况\n",
    "df_binary = df_test[df_test['llm_label'].isin(['Left', 'Right'])]\n",
    "\n",
    "# 编码\n",
    "platform_encoded = df_binary['platform'].map({'bluesky': 0, 'truthsocial': 1})\n",
    "politics_encoded = df_binary['llm_label'].map({'Left': 0, 'Right': 1})\n",
    "\n",
    "correlation = matthews_corrcoef(platform_encoded, politics_encoded)\n",
    "print(f\"Matthews Correlation Coefficient: {correlation:.3f}\")\n",
    "print(\"(1.0 = perfect correlation, 0 = no correlation, -1.0 = perfect inverse correlation)\")\n",
    "\n",
    "# 条件概率\n",
    "print(\"\\nConditional Probabilities:\")\n",
    "for platform in ['bluesky', 'truthsocial']:\n",
    "    for political in ['Left', 'Right']:\n",
    "        count = len(df_test[(df_test['platform']==platform) & (df_test['llm_label']==political)])\n",
    "        total = len(df_test[df_test['platform']==platform])\n",
    "        prob = count / total if total > 0 else 0\n",
    "        print(f\"P({political} | {platform}): {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Research Insights\n",
      "============================================================\n",
      "\n",
      "1. Platform Echo Chamber Effect:\n",
      "   - How much does platform choice correlate with political ideology?\n",
      "   - Your data can quantify this!\n",
      "\n",
      "2. Cross-Platform Political Minorities:\n",
      "Right-wing on Bluesky     2036\n",
      "Left-wing on TruthSocial   560\n",
      "\n",
      "3. Model Robustness Question:\n",
      "   - Can a model trained on platform-balanced data generalize better?\n",
      "   - Your LLM-label model is actually learning cross-platform patterns!\n",
      "\n",
      "4. Feature Importance:\n",
      "   - What words distinguish platforms vs. political stances?\n"
     ]
    }
   ],
   "source": [
    "# 生成一些分析建议\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Research Insights\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. Platform Echo Chamber Effect:\")\n",
    "print(\"   - How much does platform choice correlate with political ideology?\")\n",
    "print(\"   - Your data can quantify this!\")\n",
    "\n",
    "print(\"\\n2. Cross-Platform Political Minorities:\")\n",
    "df_minorities = pd.DataFrame({\n",
    "    'Right-wing on Bluesky': [len(df_test[(df_test['platform']=='bluesky') & (df_test['llm_label']=='Right')])],\n",
    "    'Left-wing on TruthSocial': [len(df_test[(df_test['platform']=='truthsocial') & (df_test['llm_label']=='Left')])]\n",
    "})\n",
    "print(df_minorities.T.to_string(header=False))\n",
    "\n",
    "print(\"\\n3. Model Robustness Question:\")\n",
    "print(\"   - Can a model trained on platform-balanced data generalize better?\")\n",
    "print(\"   - Your LLM-label model is actually learning cross-platform patterns!\")\n",
    "\n",
    "print(\"\\n4. Feature Importance:\")\n",
    "print(\"   - What words distinguish platforms vs. political stances?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b0234fea3f58>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n\u001b[1;32m      4\u001b[0m                         DataCollatorWithPadding, TrainingArguments, Trainer)\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"3.1.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowBasedBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBuilderConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorBasedBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# numpy compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_numpy_dev\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m  \u001b[0;31m# pyright: ignore # noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompressors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m from pandas.compat.numpy import (\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mnp_version_under1p21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# numpy versioning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/util/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pyright: reportUnusedImport = false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from pandas.util._decorators import (  # noqa:F401\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mAppender\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSubstitution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcache_readonly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m from pandas._typing import (\n\u001b[1;32m     16\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/_libs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m from pandas._libs.tslibs import (\n\u001b[1;32m     15\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/_libs/interval.pyx\u001b[0m in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/_libs/hashtable.pyx\u001b[0m in \u001b[0;36minit pandas._libs.hashtable\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/_libs/missing.pyx\u001b[0m in \u001b[0;36minit pandas._libs.missing\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/_libs/tslibs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtslibs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtslibs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlocalize_pydatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m from pandas._libs.tslibs.dtypes import (\n\u001b[1;32m     41\u001b[0m     \u001b[0mResolution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.conversion\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/_libs/tslibs/offsets.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.offsets\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/_libs/tslibs/timestamps.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.timestamps\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/_libs/tslibs/timedeltas.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.timedeltas\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/site-packages/pandas/_libs/tslibs/fields.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.fields\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WEB102/.conda/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                        DataCollatorWithPadding, TrainingArguments, Trainer)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LEN = 256\n",
    "\n",
    "# build HF datasets\n",
    "def to_hf(df):\n",
    "    # keep numeric label and rename it to 'labels'\n",
    "    tmp = df[[\"text\", \"y\", \"topic\", \"platform\"]].copy()\n",
    "    tmp = tmp.rename(columns={\"y\": \"labels\"})\n",
    "    return Dataset.from_pandas(tmp, preserve_index=False)\n",
    "\n",
    "hf = DatasetDict({\n",
    "    \"train\": to_hf(df_train),\n",
    "    \"validation\": to_hf(df_val),\n",
    "    \"test\": to_hf(df_test),\n",
    "})\n",
    "\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tok(batch[\"text\"], truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "hf_tok = hf.map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\", \"topic\", \"platform\"],  # 'labels' is kept\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tok)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1_macro = f1_score(labels, preds, average=\"macro\")\n",
    "\n",
    "    out = {\"accuracy\": acc, \"f1\": f1_macro}\n",
    "\n",
    "    # per-class F1\n",
    "    for i, name in ID2LABEL_NOISY.items():\n",
    "        out[f\"f1_{name}\"] = f1_score(\n",
    "            (labels == i).astype(int),\n",
    "            (preds == i).astype(int),\n",
    "            average=\"binary\",\n",
    "            zero_division=0,\n",
    "        )\n",
    "    return out\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(LABELS_NOISY),\n",
    "    id2label=ID2LABEL_NOISY,\n",
    "    label2id=LABEL2ID_NOISY\n",
    ").to(device)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"models_distilbert\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=200,\n",
    "    save_steps=2000,\n",
    "    seed=RANDOM_SEED,\n",
    "    dataloader_num_workers=4,\n",
    ")\n",
    "\n",
    "# handle imbalance with class weights\n",
    "use_class_weights = True\n",
    "class_counts = df_train[\"y\"].value_counts().reindex(range(len(LABELS_NOISY)), fill_value=0).values\n",
    "weights = torch.tensor(len(df_train)/np.maximum(class_counts,1), dtype=torch.float32, device=device)\n",
    "weights = weights / weights.sum() * len(LABELS_NOISY)  # normalize around 1\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # labels\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        if self.class_weights is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        else:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, model.config.num_labels),\n",
    "            labels.view(-1)\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=hf_tok[\"train\"],\n",
    "    eval_dataset=hf_tok[\"validation\"],\n",
    "    tokenizer=tok,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    class_weights=weights,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"Val metrics:\", trainer.evaluate(hf_tok[\"validation\"]))\n",
    "print(\"Test metrics:\", trainer.evaluate(hf_tok[\"test\"]))\n",
    "\n",
    "# saving model\n",
    "trainer.save_model(\"models_distilbert/best\")\n",
    "tok.save_pretrained(\"models_distilbert/best\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
